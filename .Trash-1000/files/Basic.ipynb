{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50936be5-969f-41cd-b9f4-1ea636642009",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "071918e7-d672-456c-bc25-0958e499f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from docx import Document\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from skllm import MultiLabelZeroShotGPTClassifier\n",
    "from skllm.config import SKLLMConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00c27fb1-a5f1-428c-95f0-14c1b62abf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#See notes in INSTALL.md for how to set this, DO NOT HARD CODE YOUR API KEY HERE, \n",
    "# if your repository is public, then someone will steal your API key and make you pay for their shit \n",
    "SKLLMConfig.set_openai_key(os.environ.get('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5129b91-8cbc-4359-bf2a-dc8d5e00f6ed",
   "metadata": {},
   "source": [
    "# Collect a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78ced7e9-9901-4855-980a-c3713933b193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the folder path where your Word documents are located\n",
    "folder_path = 'data'\n",
    "\n",
    "X = []\n",
    "\n",
    "# Loop over each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.docx'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Open the Word document\n",
    "        doc = Document(file_path)\n",
    "        \n",
    "        # Loop over each paragraph in the document and print its text\n",
    "        filetext=\"\"\n",
    "        for para in doc.paragraphs:\n",
    "            filetext+=para.text\n",
    "        X.append(filetext)\n",
    "\n",
    "data = pd.DataFrame(X, columns=['WritingSample'])\n",
    "\n",
    "# Step 1: Read the CSV file containing the text for 'HumanLabel'\n",
    "csv_data = pd.read_csv('data/teacher_grades.csv')\n",
    "\n",
    "# Step 2: Create a 'HumanLabel' column in your DataFrame and initialize it with empty strings\n",
    "data['HumanLabel'] = \"\"\n",
    "\n",
    "# Step 3: Iterate through the rows of your DataFrame\n",
    "for index, row in data.iterrows():\n",
    "    file_name = row['WritingSample']  # Assuming 'WritingSample' contains file names\n",
    "    matching_row = csv_data[csv_data['StudentName'] == file_name]  # Correct the column name\n",
    "    if not matching_row.empty:\n",
    "        data.at[index, 'HumanLabel'] = matching_row['Text'].values[0]\n",
    "\n",
    "# Now, the 'HumanLabel' column in your DataFrame should be populated correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923dc7af-b409-44b7-a1f1-cae37154cf81",
   "metadata": {},
   "source": [
    "# Understand Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bae5d63e-1a2b-4173-8831-330451b7c5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WritingSample</th>\n",
       "      <th>HumanLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Every year, about 1.35 million people are kill...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a world driven by technology, some recent a...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The modern world is changing at a concerningly...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Technology in today's world continues to take ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Technological improvements are occurring world...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       WritingSample HumanLabel\n",
       "0  Every year, about 1.35 million people are kill...           \n",
       "1  In a world driven by technology, some recent a...           \n",
       "2  The modern world is changing at a concerningly...           \n",
       "3  Technology in today's world continues to take ...           \n",
       "4  Technological improvements are occurring world...           "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bea9e4e-af8a-40ee-9a12-5b9dc3d73fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WritingSample</th>\n",
       "      <th>HumanLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Every year, about 1.35 million people are kill...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            WritingSample HumanLabel\n",
       "count                                                   5          5\n",
       "unique                                                  5          1\n",
       "top     Every year, about 1.35 million people are kill...           \n",
       "freq                                                    1          5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aa94aca-fb96-4217-9a8e-456bb8ea7a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"WritingSample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08e76d2a-b14e-472e-a759-6f97bd38a19a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Every year, about 1.35 million people are kill...\n",
       "1    In a world driven by technology, some recent a...\n",
       "2    The modern world is changing at a concerningly...\n",
       "3    Technology in today's world continues to take ...\n",
       "4    Technological improvements are occurring world...\n",
       "Name: WritingSample, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f108b-5bc1-4ec3-992d-7c14c3512e0d",
   "metadata": {},
   "source": [
    "# \"Develop\" a Model aka just use OpenAI's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f7be18d-5fd4-41b1-aa4d-cabeb14943a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels: ['B', 'C']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels: ['A', 'B']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels: ['A', 'C']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels: ['B', 'C']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels: ['A', 'C']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define candidate labels\n",
    "candidate_labels = [\n",
    "    \"A\",\n",
    "    \"B\",\n",
    "    \"C\",\n",
    "    \"D\",\n",
    "    \"F\"\n",
    "]\n",
    "\n",
    "# Create and fit the classifier\n",
    "clf = MultiLabelZeroShotGPTClassifier(max_labels=2) \n",
    "clf.fit(None, [candidate_labels])\n",
    "\n",
    "# Define classification prompt (without specifying the writing_sample)\n",
    "classification_prompt = (\n",
    "    \"Please be very strict when assigning scores. Anything that earns an A should be almost perfect. Bs should be extremly good. Cs should be average. Ds should be okay. Fs shuld be poor.\\n\"\n",
    "    \"This section will be scored on development. This section focuses primarily on flow and how well a student develops the main ideas in the writing. \\n\"\n",
    "    \"Please assess the student's work based on the following criteria:\\n\\n\"\n",
    "    \"Development of Main Ideas:\\n\"\n",
    "    \"1. Perfect development of main ideas (A: Perfect)\\n\"\n",
    "    \"2. Great development of main ideas (B: Great)\\n\"\n",
    "    \"3. Good development of main ideas (C: Good)\\n\"\n",
    "    \"4. Okay development of main ideas (D: Fair)\\n\"\n",
    "    \"5. Undeveloped (F: Poor)\\n\\n\"\n",
    "    \"Quality of Work:\\n\"\n",
    "    \"6. Above average work (A: Perfect)\\n\"\n",
    "    \"7. Great work (B: Very good)\\n\"\n",
    "    \"8. Good work (C: Average)\\n\"\n",
    "    \"9. Okay work (D: Fair)\\n\"\n",
    "    \"10. Below average work (F: Poor)\\n\\n\"\n",
    "    \"Flow:\\n\"\n",
    "    \"11. Writing flows perfectly (A: Perfect)\\n\"\n",
    "    \"12. Writing has a great flow (B: Great)\\n\"\n",
    "    \"13. Writing has a good flow (C: Good)\\n\"\n",
    "    \"14. The flow of this writing is confusing (D: Fair)\\n\"\n",
    "    \"15. The flow of this writing does not make sense (F: Poor)\\n\\n\"\n",
    "    \"Use of Resources or Evidence:\\n\"\n",
    "    \"16. Great use of resources or evidence (A: Perfect)\\n\"\n",
    "    \"17. Used or referenced resources, but it could have been done better (C: Good)\\n\"\n",
    "    \"18. Inadequate use of resources or evidence (F: Poor)\\n\"\n",
    "    \"Tone:\\n\"\n",
    "    \"19. Tone strengthens the writing (A: Perfect)\\n\"\n",
    "    \"20. Tone is great (B: Great)\\n\"\n",
    "    \"21. Tone is appropriate but could be better (C: Good)\\n\"\n",
    "    \"22. Tone is inconsistent or confusing (D: Fair)\\n\"\n",
    "    \"23. Tone is inappropriate (F: Poor)\\n\\n\"\n",
    "    \"Language: \\n\"\n",
    "    \"24. Exceptional use of grammar and language (A: Perfect)\\n\"\n",
    "    \"25. Great use of grammar and language (B: Great)\\n\"\n",
    "    \"26. Good use of grammar and language (C: Good)\\n\"\n",
    "    \"27. Sub-standard use of grammar and language (D: Fair)\\n\"\n",
    "    \"28. Poor use of grammar and language (F: Poor)\\n\\n\"\n",
    "    \"Please assign an overall score of A to F based on the criteria above. An A is the best score and an F is the worst score.\"\n",
    ")\n",
    "\n",
    "# Iterate through the Writing Samples and classify them\n",
    "for writing_sample in X:\n",
    "    # Generate a classification prompt (including criteria and the writing sample)\n",
    "    complete_prompt = classification_prompt + f\"\\n\\n{writing_sample}\"\n",
    "    \n",
    "    # Use the classifier to classify the writing sample\n",
    "    predicted_labels = clf.predict([complete_prompt])[0]\n",
    "    \n",
    "    # Print the classification result\n",
    "    print(\"Predicted Labels:\", predicted_labels)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d9c1ea9-2af3-4647-9e7c-3b0fcf116fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1 - Average Score: 3.5, Letter Grade: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2 - Average Score: 4.5, Letter Grade: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 3 - Average Score: 4.0, Letter Grade: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 4 - Average Score: 3.5, Letter Grade: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 5 - Average Score: 4.0, Letter Grade: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store final letter grades\n",
    "final_letter_grades = []\n",
    "\n",
    "# Define a mapping of letter grades to numerical values\n",
    "numerical_values = {\n",
    "    \"A\": 5,\n",
    "    \"B\": 4,\n",
    "    \"C\": 3,\n",
    "    \"D\": 2,\n",
    "    \"F\": 1\n",
    "}\n",
    "\n",
    "# Iterate through the Writing Samples and classify them\n",
    "for i, writing_sample in enumerate(X):\n",
    "    # Generate a classification prompt (including criteria and the writing sample)\n",
    "    complete_prompt = classification_prompt + f\"\\n\\n{writing_sample}\"\n",
    "    \n",
    "    # Use the classifier to classify the writing sample\n",
    "    predicted_labels = clf.predict([complete_prompt])[0]\n",
    "    \n",
    "    # Calculate the average score for this sample\n",
    "    average_score = sum([numerical_values[label] for label in predicted_labels]) / len(predicted_labels)\n",
    "    \n",
    "    # Custom rounding logic: Round up for scores with a decimal part of 0.5 or greater\n",
    "    rounded_grade = round(average_score) if average_score % 1 < 0.5 else int(average_score) + 1\n",
    "    \n",
    "    # Convert the rounded grade back to a letter grade\n",
    "    final_letter_grade = next(label for label, value in numerical_values.items() if value == rounded_grade)\n",
    "    \n",
    "    # Append the final letter grade to the list\n",
    "    final_letter_grades.append(final_letter_grade)\n",
    "    \n",
    "    # Print the results for this sample\n",
    "    print(f\"Sample {i + 1} - Average Score: {average_score}, Letter Grade: {final_letter_grade}\")\n",
    "\n",
    "# Now, final_letter_grades contains the letter grade for each writing sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d836021a-5fb9-494a-bd15-0ab19a02efa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add labels to the dataset and save\n",
    "data['ChatGPTLabel'] = final_letter_grades\n",
    "data.to_csv('data/classified_tips.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782d5e63-3e5e-4b4f-9d73-a3d43401169b",
   "metadata": {},
   "source": [
    "# Choose a measure of success, Choose an evaluation protocol / evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc87a258-1e39-4003-86a5-086900728d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['WritingSample', 'HumanLabel', 'ChatGPTLabel'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "124a5050-aeca-4690-990d-affb41c2c43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       WritingSample ChatGPTLabel HumanLabel\n",
      "0  Every year, about 1.35 million people are kill...            B           \n",
      "1  In a world driven by technology, some recent a...            A           \n",
      "2  The modern world is changing at a concerningly...            B           \n",
      "3  Technology in today's world continues to take ...            B           \n",
      "4  Technological improvements are occurring world...            B           \n"
     ]
    }
   ],
   "source": [
    "selected_columns = data[[\"WritingSample\", \"ChatGPTLabel\", \"HumanLabel\"]]\n",
    "print(selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87f4c4d6-c197-4666-8de8-dda3b376ec85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Check if the column 'HumanLabel' exists in your DataFrame\n",
    "if 'HumanLabel' in data.columns:\n",
    "    # Ensure the column 'HumanLabel' has compatible data types (e.g., both are strings)\n",
    "    data['HumanLabel'] = data['HumanLabel'].astype(str)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(data['HumanLabel'], data['ChatGPTLabel'])\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "else:\n",
    "    print(\"Column 'HumanLabel' not found in the DataFrame.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7dd10a-5fc6-4359-b23a-563fa0b33f9b",
   "metadata": {},
   "source": [
    "# Skipped Steps\n",
    "* Beat a baseline\n",
    "* Overfit, regularize and tune\n",
    "* Communicate with stakeholders\n",
    "* Ship an inference model\n",
    "* Monitor and maintain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd1c3eb-6af3-4d6d-992c-13fb476cc373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
